import cv2
import numpy as np

class HandAlphabetDetector:
    def __init__(self):
        self.cap = cv2.VideoCapture(0)
        self.bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=50, detectShadows=True)
        self.gesture_history = []
        self.stable_frames = 10  # Number of frames to consider for stable detection
        
    def detect_fingers_count(self, contour):
        """
        Simple finger counting based on contour analysis
        """
        try:
            # Find convex hull
            hull = cv2.convexHull(contour, returnPoints=False)
            if len(hull) > 3:
                # Find convexity defects
                defects = cv2.convexityDefects(contour, hull)
                
                if defects is not None:
                    finger_count = 0
                    for i in range(defects.shape[0]):
                        s, e, f, d = defects[i, 0]
                        start = tuple(contour[s][0])
                        end = tuple(contour[e][0])
                        far = tuple(contour[f][0])
                        
                        # Calculate angle between fingers
                        angle = self.calculate_angle(start, far, end)
                        
                        # If angle is less than 90 degrees, count as finger
                        if angle <= 90:
                            finger_count += 1
                    
                    return min(finger_count, 5)
            return 0
        except:
            return 0
    
    def calculate_angle(self, start, far, end):
        """Calculate angle between three points"""
        try:
            a = np.sqrt((end[0] - far[0])**2 + (end[1] - far[1])**2)
            b = np.sqrt((start[0] - far[0])**2 + (start[1] - far[1])**2)
            c = np.sqrt((end[0] - start[0])**2 + (end[1] - start[1])**2)
            
            angle = np.arccos((b**2 + a**2 - c**2) / (2*b*a))
            return np.degrees(angle)
        except:
            return 180
    
    def classify_gesture(self, finger_count, contour_area):
        """
        Classify hand gesture based on finger count and hand area
        """
        # Simple classification based on finger count
        if finger_count == 0:
            return "A"  # Fist
        elif finger_count == 1:
            return "D"  # One finger
        elif finger_count == 2:
            return "V"  # Two fingers (peace sign)
        elif finger_count == 3:
            return "W"  # Three fingers
        elif finger_count == 4:
            return "4"  # Four fingers
        elif finger_count == 5:
            return "B"  # Open hand
        else:
            return "?"
    
    def get_stable_gesture(self, current_gesture):
        """
        Return gesture only if it's been stable for several frames
        """
        self.gesture_history.append(current_gesture)
        
        # Keep only recent history
        if len(self.gesture_history) > self.stable_frames:
            self.gesture_history.pop(0)
        
        # Check if gesture is stable
        if len(self.gesture_history) >= self.stable_frames:
            if all(g == current_gesture for g in self.gesture_history[-self.stable_frames:]):
                return current_gesture
        
        return ""
    
    def run(self):
        print("Hand Alphabet Detection Running (OpenCV version)")
        print("Show your hand gestures to the camera")
        print("Supported gestures: A (fist), D (1 finger), V (2 fingers), W (3 fingers), B (open hand)")
        print("Press ESC to exit")
        
        while True:
            ret, frame = self.cap.read()
            if not ret:
                break
            
            # Flip frame for mirror effect
            frame = cv2.flip(frame, 1)
            height, width = frame.shape[:2]
            
            # Create region of interest (ROI) for hand detection
            roi_top, roi_bottom = 60, 300
            roi_left, roi_right = 300, 600
            
            # Draw ROI rectangle
            cv2.rectangle(frame, (roi_left, roi_top), (roi_right, roi_bottom), (0, 255, 0), 2)
            cv2.putText(frame, "Place hand here", (roi_left, roi_top - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # Extract ROI
            roi = frame[roi_top:roi_bottom, roi_left:roi_right]
            
            # Apply background subtraction
            fg_mask = self.bg_subtractor.apply(roi)
            
            # Morphological operations to clean up the mask
            kernel = np.ones((3, 3), np.uint8)
            fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)
            fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)
            
            # Find contours
            contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            detected_letter = ""
            
            if contours:
                # Find the largest contour (assuming it's the hand)
                largest_contour = max(contours, key=cv2.contourArea)
                area = cv2.contourArea(largest_contour)
                
                if area > 5000:  # Minimum area threshold
                    # Draw contour on ROI
                    cv2.drawContours(roi, [largest_contour], -1, (0, 255, 0), 2)
                    
                    # Count fingers
                    finger_count = self.detect_fingers_count(largest_contour)
                    
                    # Classify gesture
                    current_gesture = self.classify_gesture(finger_count, area)
                    
                    # Get stable gesture
                    detected_letter = self.get_stable_gesture(current_gesture)
                    
                    # Display finger count
                    cv2.putText(roi, f'Fingers: {finger_count}', (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            
            # Display detected letter
            if detected_letter:
                cv2.putText(frame, f'Detected: {detected_letter}', (50, 50), 
                           cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 0), 3)
            else:
                cv2.putText(frame, 'No stable gesture', (50, 50), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)
            
            # Show the frames
            cv2.imshow('Hand Alphabet Detection', frame)
            cv2.imshow('Hand Mask', fg_mask)
            
            # Exit on ESC key
            if cv2.waitKey(1) & 0xFF == 27:
                break
        
        self.cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    try:
        detector = HandAlphabetDetector()
        detector.run()
    except Exception as e:
        print(f"Error: {e}")
        print("Please ensure your camera is connected and not being used by another application.")
