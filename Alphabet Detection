import cv2
import mediapipe as mp
import numpy as np

# Initialize Mediapipe Hands
mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils
hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)

def classify_hand(landmarks):
    """
    landmarks: normalized landmarks (21 points).
    For now: very simple logic for demo.
    You should replace this with ML classifier for full A-Z.
    """
    # Get y-coordinates of finger tips
    tip_ids = [4, 8, 12, 16, 20]
    fingers = []

# Thumb
    if landmarks[tip_ids[0]].x < landmarks[tip_ids[0]-1].x:
        fingers.append(1)
    else:
        fingers.append(0)

    # Other 4 fingers
    for id in range(1, 5):
        if landmarks[tip_ids[id]].y < landmarks[tip_ids[id]-2].y:
            fingers.append(1)
        else:
            fingers.append(0)

    # Example rules (just for demo):
    if fingers == [0,0,0,0,0]:
        return "A"   # fist
    elif fingers == [1,1,1,1,1]:
        return "B"   # all open
    elif fingers == [0,1,1,0,0]:
        return "C"   # 2 fingers open
    else:
        return "?"
# Start webcam
cap = cv2.VideoCapture(0)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # Flip for selfie view
    frame = cv2.flip(frame, 1)
    h, w, c = frame.shape

    # Convert BGR -> RGB
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = hands.process(rgb)

    detected_alphabet = ""

    if result.multi_hand_landmarks:
        for hand_landmarks in result.multi_hand_landmarks:
            # Draw landmarks
            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            # Classify
            detected_alphabet = classify_hand(hand_landmarks.landmark)
cv2.putText(frame, f"Detected: {detected_alphabet}", (10, 50),
                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 3)

    cv2.imshow("Alphabet Detection", frame)

    if cv2.waitKey(1) & 0xFF == 27:  # ESC to quit
        break

cap.release()
cv2.destroyAllWindows()

